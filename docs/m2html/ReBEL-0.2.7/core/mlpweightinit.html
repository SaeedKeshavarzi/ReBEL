<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of mlpweightinit</title>
  <meta name="keywords" content="mlpweightinit">
  <meta name="description" content="MLPWEIGHTINIT   Initializes the weights of a ReBEL MLP feedforward neural network">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html &copy; 2003 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../menu.html">Home</a> &gt;  <a href="#">ReBEL-0.2.7</a> &gt; <a href="#">core</a> &gt; mlpweightinit.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../menu.html"><img alt="<" border="0" src="../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="menu.html">Index for .\ReBEL-0.2.7\core&nbsp;<img alt=">" border="0" src="../../right.png"></a></td></tr></table>-->

<h1>mlpweightinit
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>MLPWEIGHTINIT   Initializes the weights of a ReBEL MLP feedforward neural network</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>function [W1, B1, W2, B2, W3, B3, W4, B4] = mlpweightinit(nodes) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> MLPWEIGHTINIT   Initializes the weights of a ReBEL MLP feedforward neural network

    [W1, B1, W2, B2, W3, B3, W4, B4] = mlpweightinit(nodes)

    INPUT
             nodes        : (r-vector)  neural network layer descriptor vector [num_in num_hid1 (num_hid2) (num_hid3) num_out]

    OUTPUT
             Wi           : (matrix) ith layer weight matrix
             Bi           : (matrix) ith layer bias vector

       EXAMPLE: [W1,B1,W2,B2] = mlpweightinit([3 5 2])
            Returns the weights for a standard 2 layer network
            with 3 inputs, 5 hidden units, and 2 outputs.

       EXAMPLE: [W1,B1,W2,B2,W3,B3] = mlpweightinit([4 5 5 2])
            Returns the weights of a 3 layer network with 4 inputs,
            5 units in the first hidden layer, 5 units in the second
            hidden layer and 2 output units.

       EXAMPLE: [W1,B1,W2,B2,W3,B3,W4,B4] = mlpweightinit([5 4 2 4 1])
            Returns the weights of a 4 layer network with 5 inputs,
            4 units in the first hidden layer, 2 units in the second
            hidden layer, 5 units in the third hidden layer and 1 output unit.

   NOTE : If only one output argument is given, i.e. W = mlpWeightInit(nodes),
          then all the neural network paramaters (weights &amp; biases) are returned
          in a packed (single vector) format. See 'mlppack' and 'mlpunpack'


   See also
   <a href="mlppack.html" class="code" title="function [wh, nodes] = mlppack(W1, B1, W2, B2, W3, B3, W4, B4)">MLPPACK</a>, <a href="mlpunpack.html" class="code" title="function [W1, B1, W2, B2, W3, B3, W4, B4] = mlpunpack(nodes, wh)">MLPUNPACK</a>, <a href="mlpindexgen.html" class="code" title="function [idxW1, idxB1, idxW2, idxB2, idxW3, idxB3, idxW4, idxB4] = mlpindexgen(nodes)">MLPINDEXGEN</a></pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="mlppack.html" class="code" title="function [wh, nodes] = mlppack(W1, B1, W2, B2, W3, B3, W4, B4)">mlppack</a>	MLPPACK  ReBEL MLP neural network weight matrices vectorizer.</li></ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="../.././ReBEL-0.2.7/examples/joint_estimation/demje2.html" class="code" title="">demje2</a>	DEMJE2 Demonstrate nonlinear time series joint estimation for Mackey-Glass chaotic time series</li><li><a href="../.././ReBEL-0.2.7/examples/parameter_estimation/dempe2.html" class="code" title="">dempe2</a>	DEMPE2  Demonstrate how the ReBEL toolkit is used to train a neural network</li></ul>
<!-- crossreference -->


<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [W1, B1, W2, B2, W3, B3, W4, B4] = mlpweightinit(nodes)</a>
0002 
0003 <span class="comment">% MLPWEIGHTINIT   Initializes the weights of a ReBEL MLP feedforward neural network</span>
0004 <span class="comment">%</span>
0005 <span class="comment">%    [W1, B1, W2, B2, W3, B3, W4, B4] = mlpweightinit(nodes)</span>
0006 <span class="comment">%</span>
0007 <span class="comment">%    INPUT</span>
0008 <span class="comment">%             nodes        : (r-vector)  neural network layer descriptor vector [num_in num_hid1 (num_hid2) (num_hid3) num_out]</span>
0009 <span class="comment">%</span>
0010 <span class="comment">%    OUTPUT</span>
0011 <span class="comment">%             Wi           : (matrix) ith layer weight matrix</span>
0012 <span class="comment">%             Bi           : (matrix) ith layer bias vector</span>
0013 <span class="comment">%</span>
0014 <span class="comment">%       EXAMPLE: [W1,B1,W2,B2] = mlpweightinit([3 5 2])</span>
0015 <span class="comment">%            Returns the weights for a standard 2 layer network</span>
0016 <span class="comment">%            with 3 inputs, 5 hidden units, and 2 outputs.</span>
0017 <span class="comment">%</span>
0018 <span class="comment">%       EXAMPLE: [W1,B1,W2,B2,W3,B3] = mlpweightinit([4 5 5 2])</span>
0019 <span class="comment">%            Returns the weights of a 3 layer network with 4 inputs,</span>
0020 <span class="comment">%            5 units in the first hidden layer, 5 units in the second</span>
0021 <span class="comment">%            hidden layer and 2 output units.</span>
0022 <span class="comment">%</span>
0023 <span class="comment">%       EXAMPLE: [W1,B1,W2,B2,W3,B3,W4,B4] = mlpweightinit([5 4 2 4 1])</span>
0024 <span class="comment">%            Returns the weights of a 4 layer network with 5 inputs,</span>
0025 <span class="comment">%            4 units in the first hidden layer, 2 units in the second</span>
0026 <span class="comment">%            hidden layer, 5 units in the third hidden layer and 1 output unit.</span>
0027 <span class="comment">%</span>
0028 <span class="comment">%   NOTE : If only one output argument is given, i.e. W = mlpWeightInit(nodes),</span>
0029 <span class="comment">%          then all the neural network paramaters (weights &amp; biases) are returned</span>
0030 <span class="comment">%          in a packed (single vector) format. See 'mlppack' and 'mlpunpack'</span>
0031 <span class="comment">%</span>
0032 <span class="comment">%</span>
0033 <span class="comment">%   See also</span>
0034 <span class="comment">%   MLPPACK, MLPUNPACK, MLPINDEXGEN</span>
0035 <span class="comment">%</span>
0036 
0037 <span class="comment">%   Copyright (c) Oregon Health &amp; Science University (2006)</span>
0038 <span class="comment">%</span>
0039 <span class="comment">%   This file is part of the ReBEL Toolkit. The ReBEL Toolkit is available free for</span>
0040 <span class="comment">%   academic use only (see included license file) and can be obtained from</span>
0041 <span class="comment">%   http://choosh.csee.ogi.edu/rebel/.  Businesses wishing to obtain a copy of the</span>
0042 <span class="comment">%   software should contact rebel@csee.ogi.edu for commercial licensing information.</span>
0043 <span class="comment">%</span>
0044 <span class="comment">%   See LICENSE (which should be part of the main toolkit distribution) for more</span>
0045 <span class="comment">%   detail.</span>
0046 
0047 <span class="comment">%===============================================================================================</span>
0048 
0049 rand(<span class="string">'state'</span>,sum(100*clock));   <span class="comment">% stir the pot a bit...</span>
0050 
0051 lenNodes = length(nodes);
0052 
0053 
0054 W1 = (rand(nodes(2),nodes(1))-0.5) *sqrt(3/nodes(1));
0055 B1 = (rand(nodes(2),1)-0.5) *sqrt(3/nodes(1));
0056 
0057 
0058 <span class="comment">% two layers</span>
0059 <span class="keyword">if</span> lenNodes &gt; 2,
0060     W2 = (rand(nodes(3),nodes(2))-0.5) *sqrt(3/nodes(2));
0061     B2 = (rand(nodes(3),1)-0.5) *sqrt(3/nodes(2));
0062 <span class="keyword">end</span>
0063 
0064 <span class="comment">% three layers</span>
0065 <span class="keyword">if</span> lenNodes &gt; 3,
0066     W3 = (rand(nodes(4),nodes(3))-0.5) *sqrt(3/nodes(3));
0067     B3 = (rand(nodes(4),1)-0.5) *sqrt(3/nodes(3));
0068 <span class="keyword">end</span>
0069 
0070 <span class="comment">% four layers</span>
0071 <span class="keyword">if</span> lenNodes &gt; 4
0072     W4 = (rand(nodes(5),nodes(4))-0.5) *sqrt(3/nodes(4));
0073     B4 = (rand(nodes(5),1)-0.5) *sqrt(3/nodes(4));
0074 <span class="keyword">end</span>
0075 
0076 <span class="keyword">if</span> lenNodes &gt; 5
0077     error(<span class="string">' [ mlpWeightInit ] Only 2, 3 and 4 layer MLp neural nets supported.'</span>);
0078 <span class="keyword">end</span>
0079 
0080 
0081 <span class="comment">%--- If requesting packed weights for output</span>
0082 
0083 <span class="keyword">if</span> (nargout &lt; 2),
0084 
0085   <span class="keyword">switch</span> lenNodes
0086 
0087    <span class="keyword">case</span> 3
0088      W1 = <a href="mlppack.html" class="code" title="function [wh, nodes] = mlppack(W1, B1, W2, B2, W3, B3, W4, B4)">mlppack</a>(W1,B1,W2,B2);
0089 
0090    <span class="keyword">case</span> 4
0091      W1 = <a href="mlppack.html" class="code" title="function [wh, nodes] = mlppack(W1, B1, W2, B2, W3, B3, W4, B4)">mlppack</a>(W1,B1,W2,B2,W3,B3);
0092 
0093    <span class="keyword">case</span> 5
0094      W1 = <a href="mlppack.html" class="code" title="function [wh, nodes] = mlppack(W1, B1, W2, B2, W3, B3, W4, B4)">mlppack</a>(W1,B1,W2,B2,W3,B3,W4,B4);
0095 
0096   <span class="keyword">end</span>
0097 
0098 <span class="keyword">end</span>
0099</pre></div>
<hr><address>Generated on Tue 26-Sep-2006 10:36:21 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/">m2html</a></strong> &copy; 2003</address>
</body>
</html>