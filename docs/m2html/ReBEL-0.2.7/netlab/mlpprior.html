<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of mlpprior</title>
  <meta name="keywords" content="mlpprior">
  <meta name="description" content="MLPPRIOR Create Gaussian prior for mlp.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html &copy; 2003 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../menu.html">Home</a> &gt;  <a href="#">ReBEL-0.2.7</a> &gt; <a href="#">netlab</a> &gt; mlpprior.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../menu.html"><img alt="<" border="0" src="../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="menu.html">Index for .\ReBEL-0.2.7\netlab&nbsp;<img alt=">" border="0" src="../../right.png"></a></td></tr></table>-->

<h1>mlpprior
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>MLPPRIOR Create Gaussian prior for mlp.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>function prior = mlpprior(nin, nhidden, nout, aw1, ab1, aw2, ab2) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment">MLPPRIOR Create Gaussian prior for mlp.

    Description
    PRIOR = MLPPRIOR(NIN, NHIDDEN, NOUT, AW1, AB1, AW2, AB2)  generates a
    data structure PRIOR, with fields PRIOR.ALPHA and PRIOR.INDEX, which
    specifies a Gaussian prior distribution for the network weights in a
    two-layer feedforward network. Two different cases are possible. In
    the first case, AW1, AB1, AW2 and AB2 are all scalars and represent
    the regularization coefficients for four groups of parameters in the
    network corresponding to first-layer weights, first-layer biases,
    second-layer weights, and second-layer biases respectively. Then
    PRIOR.ALPHA represents a column vector of length 4 containing the
    parameters, and PRIOR.INDEX is a matrix specifying which weights
    belong in each group. Each column has one element for each weight in
    the matrix, using the standard ordering as defined in MLPPAK, and
    each element is 1 or 0 according to whether the weight is a member of
    the corresponding group or not.  In the second case the parameter AW1
    is a vector of length equal to the number of inputs in the network,
    and the corresponding matrix PRIOR.INDEX now partitions the first-
    layer weights into groups corresponding to the weights fanning out of
    each input unit. This  prior is appropriate for the technique of
    automatic relevance determination.

    See also
    <a href="mlp.html" class="code" title="function net = mlp(nin, nhidden, nout, outfunc, prior, beta)">MLP</a>, <a href="mlperr.html" class="code" title="function [e, edata, eprior, mse] = mlperr(net, x, t)">MLPERR</a>, <a href="mlpgrad.html" class="code" title="function [g, gdata, gprior] = mlpgrad(net, x, t)">MLPGRAD</a>, <a href="evidence.html" class="code" title="function [net, gamma, logev] = evidence(net, x, t, num)">EVIDENCE</a></pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">
</ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="demard.html" class="code" title="">demard</a>	DEMARD	Automatic relevance determination using the MLP.</li><li><a href="demev2.html" class="code" title="">demev2</a>	DEMEV2	Demonstrate Bayesian classification for the MLP.</li><li><a href="demprior.html" class="code" title="function demprior(action);">demprior</a>	DEMPRIOR Demonstrate sampling from a multi-parameter Gaussian prior.</li></ul>
<!-- crossreference -->


<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function prior = mlpprior(nin, nhidden, nout, aw1, ab1, aw2, ab2)</a>
0002 <span class="comment">%MLPPRIOR Create Gaussian prior for mlp.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">%    Description</span>
0005 <span class="comment">%    PRIOR = MLPPRIOR(NIN, NHIDDEN, NOUT, AW1, AB1, AW2, AB2)  generates a</span>
0006 <span class="comment">%    data structure PRIOR, with fields PRIOR.ALPHA and PRIOR.INDEX, which</span>
0007 <span class="comment">%    specifies a Gaussian prior distribution for the network weights in a</span>
0008 <span class="comment">%    two-layer feedforward network. Two different cases are possible. In</span>
0009 <span class="comment">%    the first case, AW1, AB1, AW2 and AB2 are all scalars and represent</span>
0010 <span class="comment">%    the regularization coefficients for four groups of parameters in the</span>
0011 <span class="comment">%    network corresponding to first-layer weights, first-layer biases,</span>
0012 <span class="comment">%    second-layer weights, and second-layer biases respectively. Then</span>
0013 <span class="comment">%    PRIOR.ALPHA represents a column vector of length 4 containing the</span>
0014 <span class="comment">%    parameters, and PRIOR.INDEX is a matrix specifying which weights</span>
0015 <span class="comment">%    belong in each group. Each column has one element for each weight in</span>
0016 <span class="comment">%    the matrix, using the standard ordering as defined in MLPPAK, and</span>
0017 <span class="comment">%    each element is 1 or 0 according to whether the weight is a member of</span>
0018 <span class="comment">%    the corresponding group or not.  In the second case the parameter AW1</span>
0019 <span class="comment">%    is a vector of length equal to the number of inputs in the network,</span>
0020 <span class="comment">%    and the corresponding matrix PRIOR.INDEX now partitions the first-</span>
0021 <span class="comment">%    layer weights into groups corresponding to the weights fanning out of</span>
0022 <span class="comment">%    each input unit. This  prior is appropriate for the technique of</span>
0023 <span class="comment">%    automatic relevance determination.</span>
0024 <span class="comment">%</span>
0025 <span class="comment">%    See also</span>
0026 <span class="comment">%    MLP, MLPERR, MLPGRAD, EVIDENCE</span>
0027 <span class="comment">%</span>
0028 
0029 <span class="comment">%    Copyright (c) Ian T Nabney (1996-2001)</span>
0030 
0031 nextra = nhidden + (nhidden + 1)*nout;
0032 nwts = nin*nhidden + nextra;
0033 
0034 <span class="keyword">if</span> size(aw1) == [1,1] 
0035 
0036     indx = [ones(1, nin*nhidden), zeros(1, nextra)]';
0037   
0038 <span class="keyword">elseif</span> size(aw1) == [1, nin]
0039   
0040     indx = kron(ones(nhidden, 1), eye(nin));
0041     indx = [indx; zeros(nextra, nin)];
0042 
0043 <span class="keyword">else</span>
0044   
0045     error(<span class="string">'Parameter aw1 of invalid dimensions'</span>);
0046     
0047 <span class="keyword">end</span>
0048 
0049 extra = zeros(nwts, 3);
0050 
0051 mark1 = nin*nhidden;
0052 mark2 = mark1 + nhidden;
0053 extra(mark1 + 1:mark2, 1) = ones(nhidden,1);
0054 mark3 = mark2 + nhidden*nout;
0055 extra(mark2 + 1:mark3, 2) = ones(nhidden*nout,1);
0056 mark4 = mark3 + nout;
0057 extra(mark3 + 1:mark4, 3) = ones(nout,1);
0058 
0059 indx = [indx, extra];
0060 
0061 prior.index = indx;
0062 prior.alpha = [aw1, ab1, aw2, ab2]';</pre></div>
<hr><address>Generated on Tue 26-Sep-2006 10:36:21 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/">m2html</a></strong> &copy; 2003</address>
</body>
</html>