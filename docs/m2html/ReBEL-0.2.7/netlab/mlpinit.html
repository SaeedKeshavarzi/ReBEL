<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of mlpinit</title>
  <meta name="keywords" content="mlpinit">
  <meta name="description" content="MLPINIT Initialise the weights in a 2-layer feedforward network.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html &copy; 2003 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../menu.html">Home</a> &gt;  <a href="#">ReBEL-0.2.7</a> &gt; <a href="#">netlab</a> &gt; mlpinit.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../menu.html"><img alt="<" border="0" src="../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="menu.html">Index for .\ReBEL-0.2.7\netlab&nbsp;<img alt=">" border="0" src="../../right.png"></a></td></tr></table>-->

<h1>mlpinit
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>MLPINIT Initialise the weights in a 2-layer feedforward network.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>function net = mlpinit(net, prior) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment">MLPINIT Initialise the weights in a 2-layer feedforward network.

    Description

    NET = MLPINIT(NET, PRIOR) takes a 2-layer feedforward network NET and
    sets the weights and biases by sampling from a Gaussian distribution.
    If PRIOR is a scalar, then all of the parameters (weights and biases)
    are sampled from a single isotropic Gaussian with inverse variance
    equal to PRIOR. If PRIOR is a data structure of the kind generated by
    MLPPRIOR, then the parameters are sampled from multiple Gaussians
    according to their groupings (defined by the INDEX field) with
    corresponding variances (defined by the ALPHA field).

    See also
    <a href="mlp.html" class="code" title="function net = mlp(nin, nhidden, nout, outfunc, prior, beta)">MLP</a>, <a href="mlpprior.html" class="code" title="function prior = mlpprior(nin, nhidden, nout, aw1, ab1, aw2, ab2)">MLPPRIOR</a>, <a href="mlppak.html" class="code" title="function w = mlppak(net)">MLPPAK</a>, <a href="mlpunpak.html" class="code" title="function net = mlpunpak(net, w)">MLPUNPAK</a></pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="mlpunpak.html" class="code" title="function net = mlpunpak(net, w)">mlpunpak</a>	MLPUNPAK Separates weights vector into weight and bias matrices.</li></ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="demhmc2.html" class="code" title="">demhmc2</a>	DEMHMC2 Demonstrate Bayesian regression with Hybrid Monte Carlo sampling.</li><li><a href="demhmc3.html" class="code" title="">demhmc3</a>	DEMHMC3 Demonstrate Bayesian regression with Hybrid Monte Carlo sampling.</li><li><a href="demolgd1.html" class="code" title="">demolgd1</a>	DEMOLGD1 Demonstrate simple MLP optimisation with on-line gradient descent</li><li><a href="demprior.html" class="code" title="function demprior(action);">demprior</a>	DEMPRIOR Demonstrate sampling from a multi-parameter Gaussian prior.</li><li><a href="demtrain.html" class="code" title="function demtrain(action);">demtrain</a>	DEMTRAIN Demonstrate training of MLP network.</li><li><a href="mdninit.html" class="code" title="function net = mdninit(net, prior, t, options)">mdninit</a>	MDNINIT Initialise the weights in a Mixture Density Network.</li></ul>
<!-- crossreference -->


<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function net = mlpinit(net, prior)</a>
0002 <span class="comment">%MLPINIT Initialise the weights in a 2-layer feedforward network.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">%    Description</span>
0005 <span class="comment">%</span>
0006 <span class="comment">%    NET = MLPINIT(NET, PRIOR) takes a 2-layer feedforward network NET and</span>
0007 <span class="comment">%    sets the weights and biases by sampling from a Gaussian distribution.</span>
0008 <span class="comment">%    If PRIOR is a scalar, then all of the parameters (weights and biases)</span>
0009 <span class="comment">%    are sampled from a single isotropic Gaussian with inverse variance</span>
0010 <span class="comment">%    equal to PRIOR. If PRIOR is a data structure of the kind generated by</span>
0011 <span class="comment">%    MLPPRIOR, then the parameters are sampled from multiple Gaussians</span>
0012 <span class="comment">%    according to their groupings (defined by the INDEX field) with</span>
0013 <span class="comment">%    corresponding variances (defined by the ALPHA field).</span>
0014 <span class="comment">%</span>
0015 <span class="comment">%    See also</span>
0016 <span class="comment">%    MLP, MLPPRIOR, MLPPAK, MLPUNPAK</span>
0017 <span class="comment">%</span>
0018 
0019 <span class="comment">%    Copyright (c) Ian T Nabney (1996-2001)</span>
0020 
0021 <span class="keyword">if</span> isstruct(prior)
0022   sig = 1./sqrt(prior.index*prior.alpha);
0023   w = sig'.*randn(1, net.nwts); 
0024 <span class="keyword">elseif</span> size(prior) == [1 1]
0025   w = randn(1, net.nwts).*sqrt(1/prior);
0026 <span class="keyword">else</span>
0027   error(<span class="string">'prior must be a scalar or a structure'</span>);
0028 <span class="keyword">end</span>  
0029 
0030 net = <a href="mlpunpak.html" class="code" title="function net = mlpunpak(net, w)">mlpunpak</a>(net, w);
0031</pre></div>
<hr><address>Generated on Tue 26-Sep-2006 10:36:21 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/">m2html</a></strong> &copy; 2003</address>
</body>
</html>