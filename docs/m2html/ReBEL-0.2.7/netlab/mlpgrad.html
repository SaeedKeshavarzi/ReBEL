<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of mlpgrad</title>
  <meta name="keywords" content="mlpgrad">
  <meta name="description" content="MLPGRAD Evaluate gradient of error function for 2-layer network.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html &copy; 2003 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../menu.html">Home</a> &gt;  <a href="#">ReBEL-0.2.7</a> &gt; <a href="#">netlab</a> &gt; mlpgrad.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../menu.html"><img alt="<" border="0" src="../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="menu.html">Index for .\ReBEL-0.2.7\netlab&nbsp;<img alt=">" border="0" src="../../right.png"></a></td></tr></table>-->

<h1>mlpgrad
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>MLPGRAD Evaluate gradient of error function for 2-layer network.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>function [g, gdata, gprior] = mlpgrad(net, x, t) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment">MLPGRAD Evaluate gradient of error function for 2-layer network.

   Description
   G = MLPGRAD(NET, X, T) takes a network data structure NET  together
   with a matrix X of input vectors and a matrix T of target vectors,
   and evaluates the gradient G of the error function with respect to
   the network weights. The error funcion corresponds to the choice of
   output unit activation function. Each row of X corresponds to one
   input vector and each row of T corresponds to one target vector.

   [G, GDATA, GPRIOR] = MLPGRAD(NET, X, T) also returns separately  the
   data and prior contributions to the gradient. In the case of multiple
   groups in the prior, GPRIOR is a matrix with a row for each group and
   a column for each weight parameter.

   See also
   <a href="mlp.html" class="code" title="function net = mlp(nin, nhidden, nout, outfunc, prior, beta)">MLP</a>, <a href="mlppak.html" class="code" title="function w = mlppak(net)">MLPPAK</a>, <a href="mlpunpak.html" class="code" title="function net = mlpunpak(net, w)">MLPUNPAK</a>, <a href="mlpfwd.html" class="code" title="function [y, z, a] = mlpfwd(net, x)">MLPFWD</a>, <a href="mlperr.html" class="code" title="function [e, edata, eprior, mse] = mlperr(net, x, t)">MLPERR</a>, <a href="mlpbkp.html" class="code" title="function g = mlpbkp(net, x, z, deltas)">MLPBKP</a></pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="consist.html" class="code" title="function errstring = consist(model, type, inputs, outputs)">consist</a>	CONSIST Check that arguments are consistent.</li><li><a href="gbayes.html" class="code" title="function [g, gdata, gprior] = gbayes(net, gdata)">gbayes</a>	GBAYES	Evaluate gradient of Bayesian error function for network.</li><li><a href="mlpbkp.html" class="code" title="function g = mlpbkp(net, x, z, deltas)">mlpbkp</a>	MLPBKP	Backpropagate gradient of error function for 2-layer network.</li><li><a href="mlpfwd.html" class="code" title="function [y, z, a] = mlpfwd(net, x)">mlpfwd</a>	MLPFWD	Forward propagation through 2-layer network.</li></ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">
</ul>
<!-- crossreference -->


<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [g, gdata, gprior] = mlpgrad(net, x, t)</a>
0002 <span class="comment">%MLPGRAD Evaluate gradient of error function for 2-layer network.</span>
0003 <span class="comment">%</span>
0004 <span class="comment">%   Description</span>
0005 <span class="comment">%   G = MLPGRAD(NET, X, T) takes a network data structure NET  together</span>
0006 <span class="comment">%   with a matrix X of input vectors and a matrix T of target vectors,</span>
0007 <span class="comment">%   and evaluates the gradient G of the error function with respect to</span>
0008 <span class="comment">%   the network weights. The error funcion corresponds to the choice of</span>
0009 <span class="comment">%   output unit activation function. Each row of X corresponds to one</span>
0010 <span class="comment">%   input vector and each row of T corresponds to one target vector.</span>
0011 <span class="comment">%</span>
0012 <span class="comment">%   [G, GDATA, GPRIOR] = MLPGRAD(NET, X, T) also returns separately  the</span>
0013 <span class="comment">%   data and prior contributions to the gradient. In the case of multiple</span>
0014 <span class="comment">%   groups in the prior, GPRIOR is a matrix with a row for each group and</span>
0015 <span class="comment">%   a column for each weight parameter.</span>
0016 <span class="comment">%</span>
0017 <span class="comment">%   See also</span>
0018 <span class="comment">%   MLP, MLPPAK, MLPUNPAK, MLPFWD, MLPERR, MLPBKP</span>
0019 <span class="comment">%</span>
0020 
0021 <span class="comment">%   Copyright (c) Ian T Nabney (1996-2001)</span>
0022 
0023 <span class="comment">% Check arguments for consistency</span>
0024 errstring = <a href="consist.html" class="code" title="function errstring = consist(model, type, inputs, outputs)">consist</a>(net, <span class="string">'mlp'</span>, x, t);
0025 <span class="keyword">if</span> ~isempty(errstring);
0026   error(errstring);
0027 <span class="keyword">end</span>
0028 [y, z] = <a href="mlpfwd.html" class="code" title="function [y, z, a] = mlpfwd(net, x)">mlpfwd</a>(net, x);
0029 delout = y - t;
0030 
0031 gdata = <a href="mlpbkp.html" class="code" title="function g = mlpbkp(net, x, z, deltas)">mlpbkp</a>(net, x, z, delout);
0032 
0033 [g, gdata, gprior] = <a href="gbayes.html" class="code" title="function [g, gdata, gprior] = gbayes(net, gdata)">gbayes</a>(net, gdata);
0034</pre></div>
<hr><address>Generated on Tue 26-Sep-2006 10:36:21 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/">m2html</a></strong> &copy; 2003</address>
</body>
</html>